{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "key_classification_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmarogge/cs280r/blob/master/key_classification_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyMdovPAKAHU",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 2: Text classification with Colab and PyTorch\n",
        "\n",
        "Emma Rogge, Tasha Schoenstein & Zilin Ma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKCmwuSH0acV",
        "colab_type": "text"
      },
      "source": [
        "## Set up\n",
        "\n",
        "###Import relevant libraries and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdi-spgB0sEi",
        "colab_type": "code",
        "outputId": "0f4fdb10-a61e-4ad9-992f-57f6bd03d6fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torchtext import data\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "## GPU check, make sure to set runtime type to \"GPU\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "962cJXPYTKyS",
        "colab_type": "text"
      },
      "source": [
        "### Read in data files from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGVWcvlk080Q",
        "colab_type": "code",
        "outputId": "50d93733-74f5-4268-ae22-a920cff866fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/sriniiyer/nl2sql/master/data/atis/train.nl\n",
        "!wget https://raw.githubusercontent.com/sriniiyer/nl2sql/master/data/atis/train.sql\n",
        "!wget https://raw.githubusercontent.com/sriniiyer/nl2sql/master/data/atis/test.nl\n",
        "!wget https://raw.githubusercontent.com/sriniiyer/nl2sql/master/data/atis/test.sql"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-10 19:46:20--  https://raw.githubusercontent.com/sriniiyer/nl2sql/master/data/atis/train.nl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 281581 (275K) [text/plain]\n",
            "Saving to: ‚Äòtrain.nl‚Äô\n",
            "\n",
            "\rtrain.nl              0%[                    ]       0  --.-KB/s               \rtrain.nl            100%[===================>] 274.98K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-12-10 19:46:20 (5.52 MB/s) - ‚Äòtrain.nl‚Äô saved [281581/281581]\n",
            "\n",
            "--2019-12-10 19:46:21--  https://raw.githubusercontent.com/sriniiyer/nl2sql/master/data/atis/train.sql\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2840349 (2.7M) [text/plain]\n",
            "Saving to: ‚Äòtrain.sql‚Äô\n",
            "\n",
            "train.sql           100%[===================>]   2.71M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-12-10 19:46:21 (27.1 MB/s) - ‚Äòtrain.sql‚Äô saved [2840349/2840349]\n",
            "\n",
            "--2019-12-10 19:46:22--  https://raw.githubusercontent.com/sriniiyer/nl2sql/master/data/atis/test.nl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24646 (24K) [text/plain]\n",
            "Saving to: ‚Äòtest.nl‚Äô\n",
            "\n",
            "test.nl             100%[===================>]  24.07K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-12-10 19:46:22 (1.94 MB/s) - ‚Äòtest.nl‚Äô saved [24646/24646]\n",
            "\n",
            "--2019-12-10 19:46:22--  https://raw.githubusercontent.com/sriniiyer/nl2sql/master/data/atis/test.sql\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 250477 (245K) [text/plain]\n",
            "Saving to: ‚Äòtest.sql‚Äô\n",
            "\n",
            "test.sql            100%[===================>] 244.61K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-12-10 19:46:23 (4.89 MB/s) - ‚Äòtest.sql‚Äô saved [250477/250477]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPJ6ihGH1Oz8",
        "colab_type": "text"
      },
      "source": [
        "##Data format\n",
        "\n",
        "We're going to use `torchtext` to handle processing the data. This library is useful for processing and batching text data in Python. More information on `torchtext` can be found [in this tutorial](https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBIuSrjYUjVF",
        "colab_type": "text"
      },
      "source": [
        "To begin, we set up two instances of the PyTorch class  one for the natural-language queries and one for the SQL query intent labels.\n",
        "Next, we create instances of the PyTorch [`data.Field`](https://torchtext.readthedocs.io/en/latest/data.html#fields) class for the input (text) and output (labels) fields.\n",
        "This class contains common text-processing datatypes that can be converted to tensors.\n",
        "\n",
        "HINT: Utilize the PyTorch's `preprocess` method on your text field objects in your dataset implementation--this method tokenizes the content of the 'text' field in an Example using `spacy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0XvgL1X6GiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We set `batch_first` = True to ensure the data is batched before it is processed.\n",
        "TEXT = data.Field(lower=True, sequential=True, include_lengths=False, batch_first=True, tokenize=\"spacy\") \n",
        "LABEL = data.Field(batch_first=True, sequential=False, unk_token=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPdPKDzo-Vf6",
        "colab_type": "text"
      },
      "source": [
        "###Implement torchtext Dataset\n",
        "Implement the class below to prepare the data for classification. It is highly recommended that you make use of the [`Example class`](https://github.com/pytorch/text/blob/master/torchtext/data/example.py) to store each corresponding text and label.\n",
        "\n",
        "#### Hints:\n",
        "- Start by populating a list with each processed, tokenized query in your dataset.\n",
        "- Each text field object in your list should then have its `label` field populated with the appropriate label.\n",
        "- Leverage the `__init__` method of the parent class, [`pytorch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiZRD-ua1Jfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Convert to standard format\n",
        "class ATIS(data.Dataset):\n",
        "    dirname = 'data'\n",
        "    name = 'atis'\n",
        "\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return len(ex.text)\n",
        "\n",
        "    def __init__(self, path, text_field, label_field, **kwargs):\n",
        "        \"\"\"Create an ATIS dataset instance given a path and fields.\n",
        "        Arguments:\n",
        "            path: Path to the data file\n",
        "            text_field: The field that will be used for text data.\n",
        "            label_field: The field that will be used for label data.\n",
        "            Remaining keyword arguments: Passed to the constructor of\n",
        "                data.Dataset.\n",
        "        \"\"\"\n",
        "        fields = [('text', text_field), ('label', label_field)]\n",
        "        \n",
        "        examples = []\n",
        "        # Get text\n",
        "        with open(path+'.nl', 'r') as f:\n",
        "            for line in f:\n",
        "                ex = data.Example()\n",
        "                # Preprocess automatically does spacy tokenization\n",
        "                ex.text = text_field.preprocess(line.strip()) \n",
        "                examples.append(ex)\n",
        "        \n",
        "        # Get labels\n",
        "        with open(path+'.sql', 'r') as f:\n",
        "            for i, line in enumerate(f):\n",
        "                label = self._get_label_from_query(line.strip())\n",
        "                examples[i].label = label\n",
        "                \n",
        "        super(ATIS, self).__init__(examples, fields, **kwargs)\n",
        "    \n",
        "    # Simple function to get question labels from query\n",
        "    def _get_label_from_query(self, query):\n",
        "        parts = query.split(' ')\n",
        "        if parts[1] == 'DISTINCT':\n",
        "            label = parts[2]\n",
        "        else:\n",
        "            label = parts[1]\n",
        "        \n",
        "        if '.' in label:\n",
        "            label = label.split('.')[-1]\n",
        "        \n",
        "        return label\n",
        "\n",
        "    @classmethod\n",
        "    def splits(cls, text_field, label_field, path='./',\n",
        "               train='train', validation='dev', test='test',\n",
        "               **kwargs):\n",
        "        \"\"\"Create dataset objects for splits of the ATIS dataset.\n",
        "        Arguments:\n",
        "            text_field: The field that will be used for the sentence.\n",
        "            label_field: The field that will be used for label data.\n",
        "            root: The root directory that the dataset's zip archive will be\n",
        "                expanded into; therefore the directory in whose trees\n",
        "                subdirectory the data files will be stored.\n",
        "            train: The filename of the train data. Default: 'train.txt'.\n",
        "            validation: The filename of the validation data, or None to not\n",
        "                load the validation set. Default: 'dev.txt'.\n",
        "            test: The filename of the test data, or None to not load the test\n",
        "                set. Default: 'test.txt'.\n",
        "            Remaining keyword arguments: Passed to the splits method of\n",
        "                Dataset.\n",
        "        \"\"\"\n",
        "\n",
        "        train_data = None if train is None else cls(\n",
        "            os.path.join(path, train), text_field, label_field, **kwargs)\n",
        "        val_data = None if validation is None else cls(\n",
        "            os.path.join(path, validation), text_field, label_field, **kwargs)\n",
        "        test_data = None if test is None else cls(\n",
        "            os.path.join(path, test), text_field, label_field, **kwargs)\n",
        "        return tuple(d for d in (train_data, val_data, test_data)\n",
        "                     if d is not None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxSO_FD-4_lg",
        "colab_type": "text"
      },
      "source": [
        "###Implement tortchtext Iterators\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH78WB2o5_nC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We will use the `ATIS.splits` class method to build the `ATIS` instances for train and test data. This method splits the data into either two (train & test) or three (train, test, validation) subsets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXPI87uI6P_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make splits for data\n",
        "train_data, test_data = ATIS.splits(TEXT, LABEL, validation=None)\n",
        "\n",
        "# Build vocabulary for data fields\n",
        "TEXT.build_vocab(train_data)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go2q9-vd6RO7",
        "colab_type": "text"
      },
      "source": [
        "Once the data is processed we build the vocabulary and then construct iterators which loop over the datasets in batches. This will be important for SGD for logistic regression and for other models later in the course."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBVa2Krb5IcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make iterator for splits\n",
        "BATCH_SIZE = 32\n",
        "train_iter = data.BucketIterator(\n",
        "    train_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)\n",
        "\n",
        "test_iter = data.Iterator(test_data, batch_size=BATCH_SIZE, sort=False, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4LNuNJChQaR",
        "colab_type": "text"
      },
      "source": [
        "### Bag-of-Words Text Representation\n",
        "####Your Naive Bayes, logistic regression and MLP classifiers will use a bag of words representation for the data. The `torchtext` iterators output tokenized natural language, which you must convert into a bag of words representation.\n",
        "---\n",
        "####HINT: Your vocabulary should be derived ONLY from your training set, not your entire dataset. Make certain that your bag-of-words representations account for this. You may have unknown words in your test set and we leave it up to you to decide the best way of handling this.\n",
        "\n",
        "Additionally, you may find the following methods for tensor manipulation useful to ensure your tensors are of the appropriate dimensions.\n",
        "\n",
        "\n",
        "\n",
        "* https://pytorch.org/docs/stable/torch.html#torch.unsqueeze\n",
        "* https://pytorch.org/docs/stable/tensors.html#torch.Tensor.scatter_\n",
        "* https://pytorch.org/docs/stable/torch.html#torch.sum\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAqr0E1ThPx9",
        "colab_type": "code",
        "outputId": "553d1f7b-d771-4d8b-d828-25248cb39232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute size of vocabulary\n",
        "vocab_size = len(TEXT.vocab.itos)\n",
        "labels_size = len(LABEL.vocab.itos)\n",
        "print(\"Size of vocab: {}\".format(vocab_size))\n",
        "\n",
        "# Given a batch, provide a bag-of-words vector.\n",
        "def batch_to_bow(batch, vocab_size):\n",
        "    # Create a tensor with dimensions (number of examples, max example length, vocab size)\n",
        "    batch_one_hot = torch.zeros(batch.shape[0], batch.shape[1], vocab_size).to(batch.device)\n",
        "    batch_one_hot.scatter_(2, batch.unsqueeze(2), 1)\n",
        "    batch_bow = batch_one_hot.sum(1)\n",
        "    return batch_bow"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocab: 862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxDMbHJG9Qpg",
        "colab_type": "text"
      },
      "source": [
        "## Establish a majority baseline\n",
        "\n",
        "By defining a lower bound on performance, we know at minimum what to expect from any reasonable system. A simple baseline for classification tasks is to measure the accuracy of prediction when the most common class is always predicted. \n",
        "\n",
        "**Write code in the cell below that, given train and test data, prints information concerning the majority baseline.**\n",
        "\n",
        "HINT: Use the `Counter` class from Python's `collections` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd8XvBof6rVa",
        "colab_type": "code",
        "outputId": "9e868389-1a54-48eb-d008-0cf994284b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "def majority_baseline_accuracy(train, test):\n",
        "  # Find majority on training data\n",
        "  counts = Counter()\n",
        "  for ex in train:\n",
        "      counts[ex.label] += 1\n",
        "\n",
        "  most_common = counts.most_common(1)[0][0]\n",
        "  print(\"Most common label: {}\".format(most_common))\n",
        "  # Evaluate accuracy on test data\n",
        "  test_counts = Counter()\n",
        "  for ex in test:\n",
        "      test_counts[ex.label] += 1\n",
        "\n",
        "  total_count = len(list(test_counts.elements()))\n",
        "  most_common_count = test_counts[most_common]\n",
        "  print('Count of most common label:', most_common_count)\n",
        "  print('Count of total things labelled:', total_count)\n",
        "  print('Portion of labels that are the most common one:', most_common_count/total_count)\n",
        "\n",
        "# Call method on train, test data \n",
        "majority_baseline_accuracy(train_data, test_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most common label: flight_id\n",
            "Count of most common label: 306\n",
            "Count of total things labelled: 448\n",
            "Portion of labels that are the most common one: 0.6830357142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNbq_QvG_XGY",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes\n",
        "\n",
        "Naive Bayes classification is based on the \"naive\" assumption that all features are independent. This dramatically reduces the number of parameters required for Bayesian classification, which utilizes Bayes' Theorem which utilizes known information ($P(Y)$, $P(X)$ and $(P(X_i|Y)$) to obtain the desired unknown probability of $P(Y|X)$. This is evaluated for each possible label and the label with greatest likelihood is the prediction for a given text. \n",
        "\n",
        "---\n",
        "Let $ c_{NB} $ be the maximum value in a vector containing the conditional probabilities of label $c$ given each word in the text. Then, we can compute $c_{NB}$ by evaluating the probability of the label overall and the probability of the label given the presence of each word contained in a given text, as \n",
        "$$ c_{NB} = \\text{argmax}_{c \\in C} \\left( \\log P(c) + \\sum_{w \\in W}\\log P(w|c) \\right) $$\n",
        "\n",
        "Where $c_{NB}$ is the naive Bayes classification of a bag of words, $C$ is the set of classifications, and $W$ is the bag of words.\n",
        "\n",
        "We can calculate $P(c) = \\frac{N_c}{N}$ where $N$ is the total number of data points in our training data and $N_c$ is the total number of data points in our training data with classification $c$. \n",
        "\n",
        "We can calculate $P(w_0 | c)$ using Laplace smoothing such that $$P(w_0 | c) = \\frac{count(w_0, c) + 1}{\\left( \\sum_{w \\in V} count(w,c)\\right) + |V|}$$ where $V$ is the vocabulary.\n",
        "\n",
        "----\n",
        "##Below, implement the NaiveBayes class methods.\n",
        " \n",
        "\n",
        "###1.  `train`: Populates the log probabilities table to contain $log(P(c))$ and $log(ùëÉ(ùë§_i|ùëê)) $ for each label for each word in the vocabulary.**\n",
        "###2.   `evaluate_performance`: Evaluates the performance of the model on given datset and prints accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwSLwSEO2uyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NaiveBayes():\n",
        "    def __init__ (self, text, label):\n",
        "        self.text = text\n",
        "        self.label = label\n",
        "        self._vocab_size = len(text.vocab.stoi)\n",
        "        self._num_labels = len(label.vocab.stoi)\n",
        "        self.log_probs = {}\n",
        "    \n",
        "    ''' \n",
        "    Helper methods which students may or may not choose to implement.\n",
        "    '''\n",
        "    def get_vocab_size(self):\n",
        "        return self._vocab_size\n",
        "\n",
        "    def get_vocab(self):\n",
        "        return self.text.vocab.stoi\n",
        "\n",
        "    def get_num_labels(self):\n",
        "        return self._num_labels\n",
        "\n",
        "    def get_labels(self):\n",
        "        return self.label.vocab.stoi\n",
        "\n",
        "    def train(self, data):\n",
        "        \"\"\"\n",
        "        Populates log probabilities table for training data.\n",
        "        \"\"\"\n",
        "        vocab = self.get_vocab()\n",
        "        labels = self.get_labels()\n",
        "        for label in labels:\n",
        "            self.log_probs[label] = {}\n",
        "\n",
        "            # Calculate the log prior (logP(c))\n",
        "            N = self.get_num_labels()\n",
        "            Nc = sum(example.label == label for example in data.examples)\n",
        "            self.log_probs[label]['log_prior'] = math.log(Nc / N)\n",
        "\n",
        "            # Calculate the log likelyhood (logP(w | c)) for all words in vocab for each label\n",
        "            self.log_probs[label]['log_likelihood'] = {}\n",
        "            for word in vocab:\n",
        "                count_wc = 0\n",
        "                sum_count_wc = 0\n",
        "                for example in data.examples:\n",
        "                    if example.label == label:\n",
        "                        count_wc += sum(token == word for token in example.text)\n",
        "                        sum_count_wc += len(example.text)\n",
        "                        Pwc = (count_wc + 1) / (sum_count_wc + len(vocab))\n",
        "                        self.log_probs[label]['log_likelihood'][word] = math.log(Pwc)\n",
        "    \n",
        "    def evaluate_performance(self, dataset):\n",
        "      \"\"\"\n",
        "      Takes a dataset and prints the model's performance that dataset.\n",
        "      \"\"\"\n",
        "      # Count the number of correct guesses\n",
        "      correct_guesses = 0\n",
        "      vocab = self.get_vocab()\n",
        "      for example in dataset.examples:\n",
        "       # For each example, find the score of each label \n",
        "        scores = {}\n",
        "        for label in self.log_probs:\n",
        "          class_prediction = self.log_probs[label]['log_prior']\n",
        "          for word in example.text:\n",
        "            if word in vocab:\n",
        "              class_prediction += self.log_probs[label]['log_likelihood'][word]\n",
        "          scores[label] = class_prediction\n",
        "\n",
        "        # Find the maximum score to determine our guess for the label\n",
        "        argmax = max(scores, key=scores.get)\n",
        "\n",
        "        # If it matches the actual label, we guessed correctly!\n",
        "        if argmax == dataset.examples[dataset.examples.index(example)].label:\n",
        "          correct_guesses += 1\n",
        "\n",
        "      # Print our accuracy\n",
        "      print('Accuracy: ', correct_guesses / len(dataset.examples))\n",
        "      return correct_guesses/len(dataset.examples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao1R0Ed5IUqm",
        "colab_type": "text"
      },
      "source": [
        "## Putting it all together\n",
        "\n",
        "If you have implemented the class methods, the following should result in a trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCfg-kyV56Kw",
        "colab_type": "code",
        "outputId": "d48cda7a-02ff-4ded-e9c4-b23e44f49d32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Instantiate and train classifier\n",
        "nb_classifier = NaiveBayes(TEXT, LABEL)\n",
        "nb_classifier.train(train_data)\n",
        "\n",
        "# Evaluate model performance\n",
        "print(\"Train: \")\n",
        "nb_classifier.evaluate_performance(train_data)\n",
        "print(\"Test: \")\n",
        "nb_classifier.evaluate_performance(test_data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: \n",
            "Accuracy:  0.8942680977392099\n",
            "Test: \n",
            "Accuracy:  0.84375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.84375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pH4ph3uHnvD",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "Unlike Naive Bayes, logistic regression calculates the conditional probabilities directly. If we let $c\\in C$ be a label, $\\mathbf{w} \\in W$ be a bag-of-words representation of a natural language query, $\\mathbf{d}$ be weights in the model tied to the compatability of $c$ and $\\mathbf{w}$, and $f$ is $\\mathbf{d}^T \\mathbf{w}$, we use the softmax to get: \n",
        "$$ p(c|\\mathbf{w}, \\mathbf{d})= \\frac{\\exp (f(\\mathbf{w},c,\\mathbf{d}))}{\\sum_{c'\\in C}\\exp(f(\\mathbf{w},c',\\mathbf{d}))}. $$\n",
        "\n",
        "The weights are learned in the process of training by using a loss function--here the cross entropy loss--to compare the results produced by the current version of the model and the target results. \n",
        "---\n",
        "###Below, implement the LogisticRegression class methods.\n",
        "####1.  `__init__` : Takes the TEXT and LABEL `data.Field` instances and initializes the model.\n",
        "####2.  `forward` : Given an input tensor, performs the forward step of the logistic regression.\n",
        "HINT: Your LogisticRegression implementation may inherit from PyTorch's [nn.Module](https://pytorch.org/docs/stable/nn.html#module) class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBdFcvg-PYBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__ (self, label, text):\n",
        "        super (LogisticRegression, self).__init__ ()\n",
        "        self._num_labels = len(label.vocab.itos)\n",
        "        self._vocab_size = len(text.vocab.itos)\n",
        "        # Linear layer\n",
        "        self.fc = nn.Linear(vocab_size, labels_size)\n",
        "    \n",
        "    def get_num_labels(self):\n",
        "        return self._num_labels\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return self._vocab_size\n",
        "\n",
        "    def forward (self, input):\n",
        "        # Apply the linear layer\n",
        "        output = self.fc(input) # Batch size by number of labels\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSIQyAvod0b1",
        "colab_type": "text"
      },
      "source": [
        "### Implement the method `train` for the LogisticRegression model.\n",
        "<b>Parameters:</b> LogisticRegression model, data iterator, criterion, optimizer and # of epochs.\n",
        "\n",
        "Trains the model for n epochs with provided optimizer and learning rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuDbDkOkdzYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train (model, data_iter, criterion, optim, n_epochs = 8):\n",
        "    loss_values = []\n",
        "    epochs = []\n",
        "    for epoch in range (n_epochs):\n",
        "        c_num = 0\n",
        "        total = 0\n",
        "        running_loss = 0.0\n",
        "        for index, batch in enumerate(data_iter):\n",
        "            # Zero parameter gradients\n",
        "            optim.zero_grad()\n",
        "\n",
        "            # Input and target\n",
        "            input = batch_to_bow(batch.text, vocab_size)\n",
        "            target = batch.label.long()\n",
        "\n",
        "            # Feed the input and hidden state to the model\n",
        "            scores = model(input)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(scores, target)\n",
        "\n",
        "            # Perform backpropogation\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            # Prepare to compute the accuracy\n",
        "            predictions = torch.argmax(scores, dim = 1)\n",
        "            total += len(target)\n",
        "            c_num += (predictions == target).sum().item()        \n",
        "            running_loss += loss.item() * len(input)\n",
        "        \n",
        "            # Report the loss every 200 steps\n",
        "            if index % 200 == 0:\n",
        "                print ('Epoch :', epoch,\n",
        "                        'Step: ', index,\n",
        "                        'Loss: ', loss.item(),\n",
        "                        'Accuracy:', float (c_num)/total)\n",
        "        epoch_loss = running_loss / len(train_data)\n",
        "        loss_values.append(epoch_loss)\n",
        "        epochs.append(epoch)\n",
        "\n",
        "    p0 = plt.figure(0)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.plot(epochs, loss_values)\n",
        "    plt.title(\"Epoch vs Loss\")\n",
        "    p0.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hkNzQy-qOZx",
        "colab_type": "text"
      },
      "source": [
        "### Implement the method `evalaute_performance`.\n",
        "This method takes a model & dataset, and returns the accuracy of the model on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFjjzy9QqNw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_performance(model, data_iter):\n",
        "    # Turn on eval mode\n",
        "    model.eval()\n",
        "    c_num = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for index, batch in enumerate(data_iter):\n",
        "            # Input and target\n",
        "            input = batch_to_bow(batch.text, model.get_vocab_size())\n",
        "            target = batch.label.long()\n",
        "\n",
        "            # Feed the input and hidden state to the model\n",
        "            scores = model(input)\n",
        "\n",
        "            # Determine the index of the maximum value for each test item\n",
        "            predictions = torch.argmax(scores, dim=1)\n",
        "\n",
        "        # Prepare to compute the accuracy\n",
        "        total += len(target)\n",
        "        c_num += (predictions == target).sum().item()\n",
        "\n",
        "    # Return the accuracy\n",
        "    return float (c_num)/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8UkUosAu9YU",
        "colab_type": "text"
      },
      "source": [
        "## Putting it all together\n",
        "\n",
        "If you have implemented the LogisticRegression class methods, the following should result in a trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL2ghDuiu8gR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate classifier\n",
        "logreg_model = LogisticRegression(LABEL, TEXT).to(device) \n",
        "print(logreg_model)\n",
        "\n",
        "# Build criterion (loss), optimizer\n",
        "loss = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.Adam(logreg_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train classifier model on training split\n",
        "epochs = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "for n in range (5, 15):\n",
        "    # Train model for n epochs\n",
        "    train(logreg_model, train_iter, loss, optimizer, n)\n",
        "    epochs.append(n)\n",
        "    # Evaluate model performance on training, test splits\n",
        "    train_acc.append(evaluate_performance(logreg_model, test_iter))\n",
        "    test_acc.append(evaluate_performance(logreg_model, test_iter))\n",
        "\n",
        "# Graph loss vs accuracy for train, test\n",
        "p1 = plt.figure(1)\n",
        "plt.title(\"Epochs vs Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "train_line = plt.plot(epochs, train_acc, 'b', label=\"Train\")\n",
        "test_line = plt.plot(epochs, test_acc, 'r', label=\"Test\")\n",
        "plt.legend()\n",
        "p1.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te35cWGOJlf9",
        "colab_type": "text"
      },
      "source": [
        "# Multilayer Perceptron\n",
        "\n",
        "An MLP is composed of at least three fully connected layers of nodes, referred to as the input, output and \"hidden\" layers. Learning occurs by adjusting the connection weights between nodes based on the amount of error in the output compared to the prediction. \n",
        "\n",
        "---\n",
        "Let the degree of error in an output node $j$ in the $n$th training query be $e_j(n) = d_j(n) - y_j(n)$, where $d$ is the true label and $y$ is the predicted label.\n",
        "\n",
        "Then we can adjust the weights to minimize the entire output layer's cumulative error:\n",
        "$$\\mathcal{E}(n)=\\frac{1}{2}\\sum_j e_j^2(n)$$\n",
        "\n",
        "The change in each weight according to gradient descent is \n",
        "$$\\Delta w_{ji} (n) = -\\eta\\frac{\\partial\\mathcal{E}(n)}{\\partial v_j(n)} y_i(n)$$.\n",
        "\n",
        "---\n",
        "##Implement the methods of the class MultiLayerPerceptron below.\n",
        "####1.  `__init__` : Takes the TEXT and LABEL `data.Field` instances and initializes the model.\n",
        "####2.  `forward` : Given an input tensor, performs the forward steps of the multilayer perceptron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1R9xjg5Jnih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiLayerPerceptron(nn.Module):\n",
        "    def __init__(self, label, text, n_hidden=128):\n",
        "        super(MultiLayerPerceptron, self).__init__()\n",
        "        self._labels_size = len(label.vocab.stoi)\n",
        "        self._vocab_size = len(text.vocab.stoi)\n",
        "        self.input2hidden = nn.Linear(self._vocab_size, n_hidden)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.hidden2output = nn.Linear(n_hidden, self._labels_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    def get_vocab_size(self):\n",
        "        return self._vocab_size\n",
        "    \n",
        "    def get_labels_size(self):\n",
        "        return self._labels_size\n",
        "\n",
        "    def forward(self, data):\n",
        "        output = self.input2hidden(data)\n",
        "        output = self.relu(output)\n",
        "        output = self.hidden2output(output)\n",
        "        output = self.softmax(output)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pso30lRKXVTb",
        "colab_type": "text"
      },
      "source": [
        "### Implement the method `train` for the MultiLayerPerceptron model.\n",
        "<b>Parameters:</b> MultiLayerPerceptron model, data iterator, criterion, optimizer and # of epochs.\n",
        "\n",
        "Trains the model for n epochs with provided optimizer and learning rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CK9FDYX01-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, data_iter, criterion, optim, n_epochs = 10):\n",
        "    loss_values = []\n",
        "    epochs = []\n",
        "    for epoch in range (n_epochs):\n",
        "        curr_loss = 0.0\n",
        "        running_loss = 0.0\n",
        "        c_num = 0\n",
        "        total = 0\n",
        "        for index, batch in enumerate(data_iter):\n",
        "            if (len(batch) == 32):\n",
        "                # Zero the parameter gradients\n",
        "                optim.zero_grad()\n",
        "                \n",
        "                # Input and target\n",
        "                input = batch_to_bow(batch.text, model.get_vocab_size())\n",
        "                target = batch.label.long()\n",
        "                \n",
        "                # Forward step\n",
        "                predictions = model(input)\n",
        "                criterion = nn.NLLLoss()\n",
        "\n",
        "                # Compute loss\n",
        "                loss = criterion(predictions, target)\n",
        "                total += len(target)\n",
        "                c_num += (predictions == target).sum().item()\n",
        "                running_loss += loss.item() * len(input)\n",
        "                \n",
        "                # Backward step\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "\n",
        "                # Report the loss every 200 steps\n",
        "                curr_loss += loss.item()\n",
        "                if index % 200 == 0:\n",
        "                    print ('Epoch :', epoch,\n",
        "                        'Step: ', index,\n",
        "                        'Loss: ', loss.item(),\n",
        "                        'Accuracy:', float (c_num)/total)\n",
        "                    \n",
        "            epoch_loss = running_loss / len(train_data)\n",
        "            loss_values.append(epoch_loss)\n",
        "            epochs.append(epoch)\n",
        "\n",
        "    p2 = plt.figure(2)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.plot(epochs, loss_values)\n",
        "    plt.title(\"Epoch vs Loss\")\n",
        "    p2.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFrkAD4JXZl6",
        "colab_type": "text"
      },
      "source": [
        "### Implement the method `evalaute_performance`.\n",
        "This method takes a model & dataset, and returns the accuracy of the model on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2SEL0YI011q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_performance(model, data_iter):\n",
        "    c_num = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for index, batch in enumerate(data_iter):\n",
        "            # Input and target\n",
        "            input = batch_to_bow(batch.text, model.get_vocab_size())\n",
        "            target = batch.label.long()\n",
        "\n",
        "            # Feed the input and hidden state to the model then determine the \n",
        "            # index of the maximum value for each test item\n",
        "            scores = model(input)\n",
        "            predictions = torch.argmax(scores, dim=1)\n",
        "\n",
        "            # Prepare to compute the accuracy\n",
        "            total += len(target)\n",
        "            c_num += (predictions == target).sum().item()\n",
        "\n",
        "            # Return the accuracy\n",
        "            print(\"Accuracy: {}\".format(float(c_num)/total))\n",
        "            return float (c_num)/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmPlANoeXsIv",
        "colab_type": "text"
      },
      "source": [
        "## Putting it all together\n",
        "\n",
        "If you have implemented the MultiLayerPerceptron class and associated methods, the following code will  train the model on the training set and evaluates its performance on both train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgmTXLMJP7CF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate classifier\n",
        "mlp_model = MultiLayerPerceptron(LABEL, TEXT).to(device)\n",
        "print(mlp_model)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "learning_rate = 0.005\n",
        "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train classifier model on training split\n",
        "epochs = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "for n in range (5, 50, 5):\n",
        "    # Train model for n epochs\n",
        "    train(mlp_model, train_iter, loss, optimizer, n)\n",
        "    epochs.append(n)\n",
        "    # Evaluate model performance on training, test splits\n",
        "    train_acc.append(evaluate_performance(mlp_model, train_iter))\n",
        "    test_acc.append(evaluate_performance(mlp_model, test_iter))\n",
        "\n",
        "# Graph loss vs accuracy for train, test\n",
        "p3 = plt.figure(3)\n",
        "plt.title(\"MLP - Epochs vs Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "train_line = plt.plot(epochs, train_acc, 'b', label=\"Train\")\n",
        "test_line = plt.plot(epochs, test_acc, 'r', label=\"Test\")\n",
        "plt.legend()\n",
        "p3.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}